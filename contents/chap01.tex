% 本文件是示例论文的一部分
% 论文的主文件是位于上级目录的 `main.tex`

\chapter{绪论}

\section{研究目的与意义}

在城市化进程加速和生活节奏日益加快的当下，外卖配送、即时出行等需求呈爆发式增长，
摩托车凭借其小巧灵活、通行便利的特性，在全球各地的城市交通体系中占据了愈发重要的地位。
无论是穿梭于大街小巷的外卖骑手，还是追求通勤效率的上班族，都将摩托车视为短途出行的优质选择。
这一市场需求的增长，有力推动了摩托车产业的蓬勃发展，其保有量在全国范围内持续攀升。

随着摩托车数量的急剧增长，涉及摩托车的交通事故也逐渐增多。头盔作为摩托车驾乘人员唯一的保护装置，能够极大减少交通事故给驾乘人员带来的伤害，尽可能地保护驾驶员和乘客的生命安全\cite{hss}。尽管国家出台了强制佩戴头盔的交通法规
来保障骑行者的生命安全，但部分骑行者安全意识淡薄，依旧心存侥幸，不佩戴头盔就上路行驶，如\ref{fig:traffic}。

当前，针对摩托车驾乘人员头盔佩戴情况的监管，主要依赖交警人工检查。然而，我国道路系统错综复杂，
交通流量庞大且情况瞬息万变，交警在维持交通秩序的同时，还要负责检查头盔佩戴情况，
工作负担极为沉重。人工检查不仅效率低下、耗费大量人力物力，而且在复杂路况和密集车流中，
极易出现漏检现象，难以确保监管工作的全面性和准确性。因此，一个摩托车驾乘人员头盔佩戴检测系统对减少人工工作量、提升检测速度和准确度有很大的意义。

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.85\textwidth]{figs/chap01/traffic}
  \caption{城市道路上摩托车驾乘人员头盔佩戴情况}
  \label{fig:traffic}
\end{figure}
\section{目标检测发展历程}

目标检测是计算机视觉领域的核心任务之一，它的发展历程如\ref{fig:his}所示。

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.9\textwidth]{figs/chap01/his.png}
  \caption{目标检测算法发展历程}
  \label{fig:his}
\end{figure}

\subsection{传统目标检测}
在深度学习兴起之前，目标检测算法高度依赖人工设计特征。受限于图像表示能力，研究者们需要设计复杂的特征表示。这一时期的代表成果深刻影响了后续目标检测技术的发展。

2001年，\textcite{Viola2001}首次在通用场景下实现了无约束的人脸实时检测。相较于同期算法，Viola-Jones(VJ)检测器在保持同等检测精度的前提下，运算速度实现了数十倍乃至数百倍的提升。该检测器运用滑动窗口，对图像内所有尺寸所有位置的窗口进行遍历，判别窗口中是否存在人脸。VJ检测器融合了“积分图像”、“特征选择”以及 “检测级联”技术，大幅提升了检测效率。

Dalal与Triggs于2005年提出方向梯度直方图(HOG)描述器，对当时的尺度不变特征变换和形状语境做出重要改进\cite{Dalal2005}。HOG描述器被设计为在密集的均匀间隔单元网格(区块)上计算，并使用重叠局部对比度归一化方法来提高精度。HOG描述器的主要目标是行人检测，如若要检测不同大小的对象，则需要让HOG检测器在保持检测窗口大小不变的情况下，对输入图像进行多次重设尺寸。

DPM(Deformable Part Models)在目标检测领域具有重要地位，该模型最早由P. Felzenszwalb在2008年提出\cite{Felzenszwalb2008}，作为 HOG 检测器的延伸版本，后续经R. Girshick等人不断优化改进\cite{Felzenszwalb2010Cascade}。DPM采用“分而治之”的思想，通过检测对象的各个部件实现目标识别。

\subsection{基于深度学习的目标检测}
2012年，\textcite{alexNet}提出了一种经典的卷积神经网络AlexNet，它的出现对深度学习发展具有里程碑式的意义。基于深度学习的目标检测算法主要分两类：基于回归的一阶段目标检测算法与基于候选区域的两阶段目标检测算法。一阶段算法直接在图像上进行目标检测，将目标检测问题转化为回归问题，直接预测目标的类别和位置，不需要生成候选框，因此检测速度非常快，能够满足实时性要求较高的应用场景，如自动驾驶、视频监控等，代表算法有YOLO系列、SDD等。两阶段算法的第一阶段是生成图像中可能包含目标的候选区域，第二阶段则是对这些候选区域进行分类和边界框回归处理，这种算法检测精度更高，但会牺牲一些检测速度。下面将对两阶段的代表算法R-CNN系列展开介绍，然后详细介绍本文使用到的一阶段的代表算法YOLO系列。

\subsubsection{R-CNN系列算法}
2014年，\textcite{rcnn}提出的R-CNN的思路为：首先通过选择性搜索\cite{selectSearch}算法来提取可能包含目标的候选框，并将候选框调整成固定大小，然后通过AlexNet进行特征提取，最后利用SVM分类器识别每个区域内的目标。尽管R-CNN在目标检测领域实现了突破性进展，但其局限性也较为突出。该模型需对数量众多且相互重叠的候选区域(单张图像通常生成超过2000个候选框)进行特征提取计算，检测速度极慢。同年，\textcite{sppnet}通过引入空间金字塔池化层(SPP)，突破了传统CNN需要固定输入尺寸的约束，实现对任意尺寸图像生成固定长度特征表示，将检测速度提升至R-CNN的20倍以上。

2015年，\textcite{fast-rcnn}提出Fast R-CNN检测器，作为对R-CNN和SPPNet的进阶优化成果，其创新地实现了在同一网络配置下同步训练检测器与边界框回归器，降低了训练和推理时间，大大提升了模型的性能。

\textcite{faster-rcnn}提出的Faster R-CNN检测器是第一个端到端的，也是第一个接近实时的深度学习检测器。它引入了RPN(Region Proposal Network)来提升检测速度和性能。RPN用于自动生成候选区域，在性能上要比选择性搜索算法好很多，推动目标检测系统从分散模块逐步整合为统一的端到端学习架构。

\subsubsection{YOLO系列算法}
2016年，\textcite{yolo}提出了YOLO算法，为目标检测任务提供了一种新的解决思路。其核心机制是利用单个卷积神经网络对整幅图像进行处理，将图像分割为多个区域后，直接预测各区域的边界框与对应类别概率，并通过概率加权对边界框进行筛选，经阈值处理后输出高置信度检测结果。与两阶段的R-CNN系列算法相比，YOLO算法在检测速度上有了极大的提升，但也存在一些问题：一是泛化能力弱，难以准确检测训练时未见过的新物体；二是空间约束大，每个网格单元仅预测两个框，不利于处理小目标群；三是定位误差大，经常误判物体位置。

YOLOv2是在YOLOv1发布一年后推出的\cite{yolov2}，无论是分类还是检测，YOLOv2都比其前身YOLOv1有了很大的改进。YOLOv2的创新点是提出了一种独特的联合训练算法，该算法能够同时利用检测数据与分类数据对目标检测器进行训练。通过标记检测图像学习目标精确定位，借助分类图像扩展模型识别类别范围、增强鲁棒性。

YOLOv3\cite{yolov3}基于YOLOv2进行改进与创新，实现了性能突破：一方面，YOLOv3修正了YOLOv2的数据加载缺陷，使模型平均精度均值(mAP)提升了两个点；另一方面，YOLOv3引入多尺度预测架构(三尺度特征金字塔)优化跨尺寸目标检测能力，并采用Darknet-53骨干网络，在COCO数据集上实现了精度与速度的平衡。

相较于YOLOv3，YOLOv4\cite{yolov4}在骨干网络和颈部网络两个关键环节进行了创新升级：骨干网络层面，摒弃原有架构，采用CSPDarknet53作为新的骨干网络，通过跨阶段部分网络(CSPNet)策略优化特征提取；颈部结构上，改进空间金字塔池化(SPP)与路径聚合网络(PAN)的引入，进一步强化多尺度特征融合能力。

YOLOv5较YOLOv4在易用性上实现了提升。除了性能上面一些微小的提升之外，YOLOv5基于PyTorch框架重构代码，简化了模型的部署，同时提供了更详尽的多语言文档支持，降低开发门槛。

YOLOv6是YOLO系列中的一次重大演变，由美团视觉团队开发\cite{yolov6}。YOLOv6对YOLOv4和YOLOv5里的PAN拓扑结构进行了强化，借助RepBlocks与CSPStackRep Blocks，更高效地从骨干网络的不同层级聚合特征。除此之外的创新还有：通过硬件感知架构设计与动态训练策略的协同创新，在速度精度平衡与部署效率层面实现突破性进展；核心架构采用EfficientRep主干网络，基于RepVGG重参数化思想构建分层模块化结构，显著提升GPU推理效率；特征融合模块重构为Rep-PAN拓扑，通过重参数化卷积增强跨尺度信息流，并结合解耦式预测头缩减冗余计算。

YOLOv7基于YOLOv6提出了一系列细粒度的改进\cite{yolov7}。提出计划的重新参数化模型，将梯度传播路径概念应用于不同网络层；针对多输出层模型训练，引入由粗到细的引导标签分配的新方法；为对象检测器提出 “扩展” 和 “复合缩放” 方法，有效利用参数和计算。这些改进和优化策略，在不牺牲速度的情况下显著提高了准确率，是YOLO系列的重要进步。

相较于之前的YOLO版本，YOLOv8在准确度和速度方面实现了更优的性能，延续了YOLOv5用户友好的特点，进一步增强了易用性。YOLOv8采用无锚分割Ultralytics head，提升了检测的准确性与速度。YOLOv8 由Ultralytics维护，提供了针对检测、分割、分类和姿势检测等特定任务的多种专用模型。

相较于前代模型，2024年提出的YOLOv9采用全新思路，解决了深度神经网络信息丢失的问题\cite{yolov9}。YOLOv9的核心创新在于两大关键技术：一方面，引入可编程梯度信息(PGI)，通过辅助可逆分支完整保留输入信息，为目标函数计算提供充足依据，确保梯度更新更精准有效；另一方面，提出广义高效层聚合网络(GELAN)，作为ELAN架构的通用轻量化版本，基于梯度路径规划设计，最大化网络信息流，高效整合特征信息辅助预测。

同为2024年提出的YOLOv10相较于前代模型，刷新/了速度与准确度上限，实现了真正的实时检测\cite{yolov10}。YOLOv10的核心创新在于：一是采用NMS-Free检测，基于双重标签分配(一对多和一对一)及一致匹配度量的训练策略，推理时仅用一对一head，提升推理速度、简化部署、增强训练监督；二是运用整体效率-准确度驱动设计，通过轻量级分类head、空间通道解耦下采样和等级引导块设计，在优化模型各组件的同时有效降低计算成本。

2024年9月发布的YOLOv11历经一系列架构改良，聚焦于在无损检测准确性的前提下，全力提升计算效率。YOLO11创新性地引入了C3k2模块与C2PSA块等关键组件。C3k2模块作为跨阶段部分(CSP)瓶颈的高效计算实现，取代了骨干网络和颈部网络中的C2f块。C2PSA块紧跟SPPF模块之后，这种全新的注意力机制，使模型能够更为高效地聚焦于图像内的关键区域，精准识别目标物体。YOLOv11的网络架构将在下一章进行详细介绍。




% 2012 年，AlexNet的提出推动了深度学习在目标识别领域的广泛应用\cite{alexNet}。随后，R - CNN 系列\cite{rcnn}、
% Fast R - CNN\cite{fast-rcnn}、Faster R - CNN\cite{faster-rcnn} 等两阶段检测方法不断改进，显著提升了检测精度和效率。SSD 
% 和 YOLO 系列作为单阶段检测方法，以不同的方式实现了高效的目标检测。其中，YOLO 系列将
% 目标检测转化为回归问题，极大地提高了检测速度，并且后续版本不断优化，加入了多尺度训练等技术，
% 以应对不同尺寸物体的检测需求。

\section{YOLO在交通安全领域的应用}
YOLO系列算法凭借出色的检测速度和准确性在交通安全领域得到了广泛的应用。在车辆检测、行人检测以及道路检测方面均表现出强大的应用潜力。

在车辆检测方面，\textcite{ex1}基于YOLOv8算法，提出了结合Transformer结构全局特征提取能力的模块C2Former代替C2f模块，提升了算法在小目标、遮挡目标等场景下对交通车辆检测的精度。\textcite{ex2}针对雾天场景下的车辆检测需求，引入注意力模块(CBAM、NAM、SimAM)和BiFPN结构优化YOLO-V5s/V5l，并对比了YOLO-V5/V8系列模型的性能，优化了算法在雾天中对车辆的检测性能。

在行人检测方面，\textcite{ex3}基于YOLOv7将ELAN-SA模块与LGA模块相结合，增强了特征提取能力，在遮挡和小目标行人检测方面表现出很强的性能。\textcite{ex4}基于YOLOv11，融合RepConv来改进C3k2模块，设计全新的颈部结构MBFPN，提升行人特征提取与融合能力，提出了复杂场景下的轻量化行人检测算法。

在道路检测方面，\textcite{ex5}提出基于YOLOv8n的轻量化改进算法 EMF-YOLO，通过引入增强型特征融合金字塔EFFPN、可变形注意力机制和多尺度边缘敏感性增强模块MESA等，在提高对道路缺陷检测精度的同时实现了较好的轻量化性能。 

YOLO算法凭借其高效性与准确性，已在交通、工业、医疗等多个领域发挥其作用，提供了精准的实时监测能力，推动各个行业的智能化发展。

\section{研究与设计内容}
本文旨在设计并实现一套摩托车驾乘人员头盔佩戴检测系统，工作分为两个部分：模型训练和系统开发。

在模型训练阶段，主要开展两方面工作：
一是优化数据标注，针对驾驶员及最多三名乘客(训练数据集中，最多 只出现了一名驾驶员携带三名乘客)各自的头盔佩戴情况，细化设置了18个标签，相较于传统二分类标注，能提供更详尽的头盔佩戴信息；二是训练两个关键模型，分别用于识别摩托车驾乘人员的头盔佩戴状态，以及驾驶员id。训练过程中，采用YOLOv11n、YOLOv11s及YOLOv11m三种模型训练来比较效果，并通过调整训练轮次(epoch)优化检测精度。

系统基于浏览器/服务器(B/S)架构开发。B端浏览器为用户提供了两个操作页面，一个是用于上传图片或视频以请求检测的页面，用户可通过该页面发起检测需求；另一个是数据查询页面，用户能从该页面向服务端数据库发送历史检测结果查询请求，还可以对驾驶人、记录时间、记录地点等字段进行过滤。查询得到的结果会以柱状图、折线图等可视化的形式在页面呈现，为后续制定执法策略提供数据支持。S端服务器负责处理浏览器传来的请求，当接收到用户上传的图片或视频后，先利用第一个模型预测图片中的头盔佩戴情况，之后对目标区域进行裁剪，再使用第二个模型检测目标区域的驾驶人员，最后将检测结果保存到数据库中。\ref{fig:source}和\ref{fig:result}表示了输入图片和检测结果。

\begin{figure}[!htb]
  \centering
  \begin{minipage}{0.45\textwidth} % 调整宽度以适应需求，两张图总宽度接近1
      \centering
      \includegraphics[width=\textwidth]{figs/chap01/source.jpg}
      \caption{选择图片}
      \label{fig:source}
  \end{minipage}
  \hfill % 使两张图片之间保持一定距离
  \begin{minipage}{0.45\textwidth}
      \centering
      \includegraphics[width=\textwidth]{figs/chap01/result.png}
      \caption{检测结果}
      \label{fig:result}
  \end{minipage}
\end{figure}


\section{章节安排}
本文共包含六个章节，每一章的主要内容如下：

第一章：绪论。本章首先介绍了本文的研究目的与意义，对目标检测的发展历程进行概述，详细介绍了YOLO系列算法的发展过程及其在交通安全领域的应用现状，最后说明了本文的研究内容。

第二章：YOLO算法相关理论。本章主要介绍了YOLOv11算法的网络结构和损失函数。网络结构方面主要介绍主干网络、颈部网络和检测头。损失函数主要介绍边界框回归损失函数、分类损失函数和分布损失函数。

第三章：数据集构建及训练参数设置。本章介绍了本文的数据集来源以及为解决类别不平衡对数据集做的增强处理，分析了增强之后的标签数量分布情况，然后介绍了本文的实验环境和训练参数设置。

第四章：实验结果与分析。本章首先介绍了本文使用到的目标检测模型检测精度和速度两方面的评价指标，展示了YOLOv11n、YOLOv11s和YOLOv11m这三个模型的训练结果，对比分析了上述三个模型的损失函数、精度、召回率、mAP以及检测速度。并总结了不同模型各自适用的场景。

第五章：检测系统的设计与实现。本章主要介绍了检测系统的软件设计与开发过程。从需求分析、系统架构、前端开发和后端开发这四个方面展开。

第六章：总结与展望。本章为本文的最后一张，对本文所做的工作进行总结，并展望目标检测技术在交通安全领域的未来的发展情况。
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main.tex"
%%% End:
